{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81499fd",
   "metadata": {},
   "source": [
    "# Innomatics | Data Science | Hiring Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356f714c",
   "metadata": {},
   "source": [
    "Assume that you are working as a Data Analyst Intern with Uber.\n",
    "Your first assignment as an intern here is to perform analysis and ML modelling on rides data recorded between 2009-01-01 and \n",
    "2015-06-30.\n",
    "\n",
    "Download the dataset by CLICKING HERE.\n",
    "\n",
    "Questions are either single correct or multiple correct MCQ question. Answer carefully.\n",
    "\n",
    "Make sure to properly present all solutions in a Jupyter Notebook with proper heading and formatting. \n",
    "Upload the Jupyter Notebook at the end of this quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a917acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path=\"uber_rides_data.xlsx - sample_train.csv\"\n",
    "# Defining the chunk size (number of rows to read at a time)\n",
    "chunk_size = 10000\n",
    "\n",
    "# Initializing an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Opening the file in chunks and process each chunk\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "    data.append(chunk)\n",
    "\n",
    "# Combining all chunks into a single DataFrame if required\n",
    "df = pd.concat(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0860fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24238194</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06 UTC</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27835199</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56 UTC</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44984355</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00 UTC</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25894730</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21 UTC</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17610152</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00 UTC</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ride_id  fare_amount          pickup_datetime  pickup_longitude  \\\n",
       "0  24238194          7.5  2015-05-07 19:52:06 UTC        -73.999817   \n",
       "1  27835199          7.7  2009-07-17 20:04:56 UTC        -73.994355   \n",
       "2  44984355         12.9  2009-08-24 21:45:00 UTC        -74.005043   \n",
       "3  25894730          5.3  2009-06-26 08:22:21 UTC        -73.976124   \n",
       "4  17610152         16.0  2014-08-28 17:47:00 UTC        -73.925023   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0        40.738354         -73.999512         40.723217                1  \n",
       "1        40.728225         -73.994710         40.750325                1  \n",
       "2        40.740770         -73.962565         40.772647                1  \n",
       "3        40.790844         -73.965316         40.803349                3  \n",
       "4        40.744085         -73.973082         40.761247                5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25012904",
   "metadata": {},
   "source": [
    "### What is the shape of given dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "038957da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57238bdb",
   "metadata": {},
   "source": [
    "### How many integer columns(by default) are given in the dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f422619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Integer Columns: 2\n",
      "List of Integer Columns: Index(['ride_id', 'passenger_count'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "integer_columns = df.select_dtypes(include=['int']).columns\n",
    "integer_column_count = len(integer_columns)\n",
    "\n",
    "print(\"Count of Integer Columns:\", integer_column_count)\n",
    "print(\"List of Integer Columns:\", integer_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0875b04",
   "metadata": {},
   "source": [
    "### How many missing values exists in 'dropoff_longitude' column?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f672248e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Missing Values in 'dropoff_longitude' column: 1\n"
     ]
    }
   ],
   "source": [
    "missing_values_count = df['dropoff_longitude'].isnull().sum()\n",
    "\n",
    "print(\"Number of Missing Values in 'dropoff_longitude' column:\", missing_values_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471966ab",
   "metadata": {},
   "source": [
    "### What is the data type of ' pickup_datetime' feature in your data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e852e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type of 'pickup_datetime' Feature: object\n"
     ]
    }
   ],
   "source": [
    "pickup_datetime_dtype = df['pickup_datetime'].dtypes\n",
    "\n",
    "print(\"Data Type of 'pickup_datetime' Feature:\", pickup_datetime_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0b6405",
   "metadata": {},
   "source": [
    "### Which of the following is the correct syntax to convert 'pickup_datetime' to datetime datatype?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f16266eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type of 'pickup_datetime' Feature: datetime64[ns, UTC]\n"
     ]
    }
   ],
   "source": [
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "pickup_datetime_dtype = df['pickup_datetime'].dtypes\n",
    "print(\"Data Type of 'pickup_datetime' Feature:\", pickup_datetime_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21150570",
   "metadata": {},
   "source": [
    "### Which function can be used to remove null values from the dataframe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbb871ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ride_id              0\n",
       "fare_amount          0\n",
       "pickup_datetime      0\n",
       "pickup_longitude     0\n",
       "pickup_latitude      0\n",
       "dropoff_longitude    0\n",
       "dropoff_latitude     0\n",
       "passenger_count      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdd3c1f",
   "metadata": {},
   "source": [
    "### What is the average fare amount?\n",
    "\n",
    "Remove the null values from the dataframe to answer the following question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da23bdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Fare Amount: 11.359891549457748\n"
     ]
    }
   ],
   "source": [
    "df.dropna(subset=['fare_amount'], inplace=True)\n",
    "\n",
    "# Calculate the average fare amount\n",
    "average_fare_amount = df['fare_amount'].astype(float).mean()\n",
    "\n",
    "print(\"Average Fare Amount:\", average_fare_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8150d387",
   "metadata": {},
   "source": [
    "###  Calculate distance between each pickup and dropoff points using Haversine formula. \n",
    "What is the median haversine distance between pickup and dropoff location according to the given dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e491f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Haversine Distance: 2.1209923961833708\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    r = 6371  # Radius of the Earth in kilometers\n",
    "    return c * r\n",
    "\n",
    "\n",
    "df['haversine_distance'] = df.apply(lambda row: haversine(row['pickup_latitude'], row['pickup_longitude'], \n",
    "                                                          row['dropoff_latitude'], row['dropoff_longitude']), axis=1)\n",
    "median_haversine_distance = df['haversine_distance'].median()\n",
    "\n",
    "print(\"Median Haversine Distance:\", median_haversine_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc46c4c",
   "metadata": {},
   "source": [
    "### What is the maximum haversine distance between pickup and dropoff location according to the given dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad5110f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Haversine Distance: 16409.239135313164\n"
     ]
    }
   ],
   "source": [
    "max_haversine_distance = df['haversine_distance'].max()\n",
    "\n",
    "print(\"Maximum Haversine Distance:\", max_haversine_distance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aaac25",
   "metadata": {},
   "source": [
    "### How many rides have 0.0 haversine distance between pickup and dropoff location according to the given dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed649b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rides with 0.0 Haversine Distance: 5632\n"
     ]
    }
   ],
   "source": [
    "zero_distance_rides = df[df['haversine_distance'] == 0.0]\n",
    "count_zero_distance_rides = len(zero_distance_rides)\n",
    "\n",
    "print(\"Number of Rides with 0.0 Haversine Distance:\", count_zero_distance_rides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05994e0a",
   "metadata": {},
   "source": [
    "### What is the mean 'fare_amount' for rides with 0 haversine distance?\n",
    "\n",
    "Do you sense something fishy? Try to analyze, and give your expert opinion in Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36e9aee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 'fare_amount' for Rides with 0.0 Haversine Distance: 11.585317826704546\n"
     ]
    }
   ],
   "source": [
    "mean_fare_amount_for_zero_distance = df[df['haversine_distance'] == 0.0]['fare_amount'].mean()\n",
    "\n",
    "print(\"Mean 'fare_amount' for Rides with 0.0 Haversine Distance:\", mean_fare_amount_for_zero_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c15b00",
   "metadata": {},
   "source": [
    "As for whether something fishy is going on, the fact that there are rides with a Haversine \n",
    "distance of 0.0 suggests that these rides have the same pickup and dropoff coordinates, which \n",
    "is unusual for a taxi or rideshare service. It could indicate potential errors or anomalies in \n",
    "the dataset. Further investigation may be needed to understand why there are rides with zero \n",
    "Haversine distance and whether they should be excluded or handled differently in your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6f0788",
   "metadata": {},
   "source": [
    "### What is the maximum 'fare_amount' for a ride?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15288b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum 'fare_amount' for a Ride: 499.0\n"
     ]
    }
   ],
   "source": [
    "max_fare_amount = df['fare_amount'].max()\n",
    "\n",
    "print(\"Maximum 'fare_amount' for a Ride:\", max_fare_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5425387",
   "metadata": {},
   "source": [
    "### What is the haversine distance between pickup and dropoff location for the costliest ride?\n",
    "\n",
    "Do you sense something fishy? Try to analyze, and give your expert opinion in Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65bc6181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haversine Distance for the Costliest Ride: 0.0007899213191009994\n"
     ]
    }
   ],
   "source": [
    "costliest_ride = df[df['fare_amount'] == df['fare_amount'].max()]\n",
    "\n",
    "# Calculate the Haversine distance for the costliest ride\n",
    "haversine_distance_costliest_ride = costliest_ride['haversine_distance'].values[0]\n",
    "\n",
    "print(\"Haversine Distance for the Costliest Ride:\", haversine_distance_costliest_ride)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887dc9a2",
   "metadata": {},
   "source": [
    " As for whether something fishy is going on, it's important to analyze the results \n",
    " and potentially investigate further if the calculated Haversine distance for the \n",
    " costliest ride seems unrealistic. If the distance appears to be extremely large or \n",
    " small compared to the fare amount, it could indicate errors or anomalies in the dataset.\n",
    " Further data validation or cleaning may be required to ensure the accuracy of the dataset and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d003d54a",
   "metadata": {},
   "source": [
    "### How many rides were recorded in the year 2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "090b7d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rides Recorded in 2014: 29968\n"
     ]
    }
   ],
   "source": [
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])  # Convert the column to datetime if not already done\n",
    "\n",
    "# Extract the year from the datetime column\n",
    "df['pickup_year'] = df['pickup_datetime'].dt.year\n",
    "\n",
    "# Count the number of rides recorded in the year 2014\n",
    "rides_in_2014 = len(df[df['pickup_year'] == 2014])\n",
    "\n",
    "print(\"Number of Rides Recorded in 2014:\", rides_in_2014)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8866a6d",
   "metadata": {},
   "source": [
    "### How many rides were recorded in the first quarter of 2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8b8d067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rides Recorded in the First Quarter of 2014: 7687\n"
     ]
    }
   ],
   "source": [
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])  # Convert the column to datetime if not already done\n",
    "\n",
    "# Filter the DataFrame for the first quarter of 2014 (January to March)\n",
    "q1_2014_rides = df[(df['pickup_datetime'].dt.year == 2014) & (df['pickup_datetime'].dt.quarter == 1)]\n",
    "\n",
    "# Count the number of rides in the first quarter of 2014\n",
    "rides_in_q1_2014 = len(q1_2014_rides)\n",
    "\n",
    "print(\"Number of Rides Recorded in the First Quarter of 2014:\", rides_in_q1_2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f507db",
   "metadata": {},
   "source": [
    "### On which day of the week in September 2010, maximum rides were recorded ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2115bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day of the Week with Maximum Rides in September 2010: Thursday\n",
      "Number of Rides on the Maximum Day: 457\n"
     ]
    }
   ],
   "source": [
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])  # Convert the column to datetime if not already done\n",
    "\n",
    "# Filter the DataFrame for rides in September 2010\n",
    "september_2010_rides = df[(df['pickup_datetime'].dt.year == 2010) & (df['pickup_datetime'].dt.month == 9)]\n",
    "\n",
    "# Calculate the day of the week for each ride and count the occurrences\n",
    "day_of_week_counts = september_2010_rides['pickup_datetime'].dt.day_name().value_counts()\n",
    "\n",
    "# Find the day of the week with the maximum number of rides\n",
    "max_rides_day = day_of_week_counts.idxmax()\n",
    "max_rides_count = day_of_week_counts.max()\n",
    "\n",
    "print(\"Day of the Week with Maximum Rides in September 2010:\", max_rides_day)\n",
    "print(\"Number of Rides on the Maximum Day:\", max_rides_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28d8ae9",
   "metadata": {},
   "source": [
    "### Apply a Machine Learning Algorithm to predict the fare amount given following input features:\n",
    "passenger_count, distance and ride_week_day.\n",
    "\n",
    "Perform a 70-30 split of data.\n",
    "\n",
    "Which algorithm gives the least adjusted R square value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "144d71e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculating haversine distance (assuming you have latitude and longitude columns)\n",
    "from haversine import haversine\n",
    "\n",
    "# Filtering rows with valid longitude values (-180 to 180 degrees)\n",
    "df = df[(df['pickup_longitude'] >= -180) & (df['pickup_longitude'] <= 180)]\n",
    "df = df[(df['dropoff_longitude'] >= -180) & (df['dropoff_longitude'] <= 180)]\n",
    "\n",
    "# Filtering  rows with valid latitude values (-90 to 90 degrees)\n",
    "df = df[(df['pickup_latitude'] >= -90) & (df['pickup_latitude'] <= 90)]\n",
    "df = df[(df['dropoff_latitude'] >= -90) & (df['dropoff_latitude'] <= 90)]\n",
    "\n",
    "\n",
    "df['haversine_distance'] = df.apply(lambda row: haversine((row['pickup_latitude'], row['pickup_longitude']), (row['dropoff_latitude'], row['dropoff_longitude'])), axis=1)\n",
    "\n",
    "# Extracting year and week day from pickup_datetime\n",
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "df['pickup_year'] = df['pickup_datetime'].dt.year\n",
    "df['ride_week_day'] = df['pickup_datetime'].dt.weekday\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3120a4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R-squared values:\n",
      "Linear Regression: 0.0007404294806256928\n",
      "Decision Tree Regression: 0.4567656965708632\n",
      "Random Forest Regression: 0.6316398060981403\n",
      "KNN Regression: 0.6825746408607534\n",
      "The algorithm with the least adjusted R-squared is: Linear Regression\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Assuming 'df' is your DataFrame with the relevant columns\n",
    "\n",
    "# Prepare the features and target variable\n",
    "X = df[['passenger_count', 'haversine_distance', 'ride_week_day']]\n",
    "y = df['fare_amount']\n",
    "\n",
    "# Split the data into training and testing sets (70-30 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the regression models\n",
    "linear_reg = LinearRegression()\n",
    "decision_tree_reg = DecisionTreeRegressor()\n",
    "random_forest_reg = RandomForestRegressor()\n",
    "knn_reg = KNeighborsRegressor()\n",
    "\n",
    "# Create a dictionary of models\n",
    "models = {\n",
    "    'Linear Regression': linear_reg,\n",
    "    'Decision Tree Regression': decision_tree_reg,\n",
    "    'Random Forest Regression': random_forest_reg,\n",
    "    'KNN Regression': knn_reg\n",
    "}\n",
    "\n",
    "# Dictionary to store adjusted R-squared values for each model\n",
    "adjusted_r2_scores = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    n = len(y_test)\n",
    "    p = len(X_test.columns)\n",
    "    adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "    \n",
    "    adjusted_r2_scores[model_name] = adjusted_r2\n",
    "\n",
    "# Find the algorithm with the least adjusted R-squared\n",
    "least_adjusted_r2_algorithm = min(adjusted_r2_scores, key=adjusted_r2_scores.get)\n",
    "\n",
    "# Print the adjusted R-squared values for each algorithm\n",
    "print(\"Adjusted R-squared values:\")\n",
    "for model_name, adjusted_r2 in adjusted_r2_scores.items():\n",
    "    print(f\"{model_name}: {adjusted_r2}\")\n",
    "\n",
    "# Print the algorithm with the least adjusted R-squared\n",
    "print(f\"The algorithm with the least adjusted R-squared is: {least_adjusted_r2_algorithm}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a956ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
